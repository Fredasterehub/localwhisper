--- a/config.py
+++ b/config.py
@@ -13,7 +13,7 @@
 # Whisper Settings
 WHISPER_MODEL_SIZE = "large-v3"
 # "float16" for GPU (requires VRAM), "int8" for efficiency if needed
-COMPUTE_TYPE = "int8" # Optimized for Speed/VRAM 
+COMPUTE_TYPE = "float16" # Optimized for semantic correctness on modern GPUs
 DEVICE = "cuda" # or "cpu"
 
 # Ollama Settings
--- a/main.py
+++ b/main.py
@@ -127,6 +127,19 @@
 
     processing_lock = threading.Lock()
     stop_processing_flag = False
+
+    def get_success_hold_s() -> float:
+        try:
+            return max(0.05, float(settings.get("success_hold_ms")) / 1000.0)
+        except Exception:
+            return 0.35
+
+    def should_refine_llm(confidence: str) -> bool:
+        if not settings.get("use_intelligence"):
+            return False
+        want = str(settings.get("llm_refine_min_confidence") or "high").lower()
+        rank = {"high": 3, "medium": 2, "low": 1, "silence": 0, "unknown": 0}
+        return rank.get(confidence, 0) >= rank.get(want, 3)
     
     def pipeline_worker():
         nonlocal stop_processing_flag
@@ -163,7 +176,7 @@
                      if raw_text:
                          # log(f"Raw ({time.time()-start_process:.2f}s): {raw_text}", "debug")
                          
-                         if settings.get("use_intelligence"):
+                         if should_refine_llm(getattr(transcriber, "last_confidence", "unknown")):
                              final_text = intelligence.refine_text(raw_text)
                          else:
                              final_text = raw_text # Raw Mode
@@ -172,7 +185,7 @@
                          
                          injector.type_text(final_text)
                          ui_queue.put("SUCCESS")
-                         time.sleep(1.0)
+                         time.sleep(get_success_hold_s())
                      else:
                          pass 
                  except Exception as e:
@@ -187,6 +200,8 @@
         def _job():
             if processing_lock.acquire(blocking=False):
                 try:
+                    if stop_processing_flag:
+                        return
                     ui_queue.put("LISTENING")
                     audio_data = audio.listen_single_segment()
                     if len(audio_data) > 0:
@@ -196,11 +211,14 @@
                         
                         raw_text = transcriber.transcribe(audio_data, language=lang_code)
                         if raw_text:
-                            final_text = intelligence.refine_text(raw_text)
-                        else:
-                            final_text = raw_text # Raw Mode
+                            if should_refine_llm(getattr(transcriber, "last_confidence", "unknown")):
+                                final_text = intelligence.refine_text(raw_text)
+                            else:
+                                final_text = raw_text
+
+                            injector.type_text(final_text)
                             ui_queue.put("SUCCESS")
-                            time.sleep(1)
+                            time.sleep(get_success_hold_s())
                 except Exception:
                     pass
                 finally:
@@ -237,6 +255,48 @@
     
     threading.Thread(target=start_hotkey, daemon=True).start()
 
+    def start_ptt_key_listener():
+        # Optional single-key PTT binding from Settings (e.g., `, space).
+        ignore_keys = {"ctrl", "shift", "alt", "meta", "cmd", "win"}
+
+        def normalize_key(k):
+            try:
+                # KeyCode -> character (e.g. '`')
+                if hasattr(k, "char") and k.char:
+                    return str(k.char).lower()
+            except Exception:
+                pass
+
+            try:
+                # Special keys (space, enter, etc.)
+                if isinstance(k, keyboard.Key):
+                    name = str(k).replace("Key.", "").lower()
+                    return name
+            except Exception:
+                pass
+
+            return None
+
+        def on_press(k):
+            try:
+                if settings.get("mode") != "push_to_talk":
+                    return
+                wanted = str(settings.get("push_to_talk_key") or "").lower()
+                if not wanted or wanted in ignore_keys:
+                    return
+                if normalize_key(k) == wanted:
+                    trigger_ptt_pass()
+            except Exception:
+                pass
+
+        try:
+            with keyboard.Listener(on_press=on_press) as listener:
+                listener.join()
+        except Exception:
+            pass
+
+    threading.Thread(target=start_ptt_key_listener, daemon=True).start()
+
     def on_quit():
         stop_processing_flag = True
         if audio: audio.stop_recording()
--- a/core/audio.py
+++ b/core/audio.py
@@ -6,12 +6,15 @@
 import time
 import os
 import requests
+import math
 from core.settings import manager as settings
 from core.logger import log
 
 class AudioEngine:
     def __init__(self):
         self.sample_rate = config.SAMPLE_RATE
+        if self.sample_rate != 16000:
+            log(f"Silero VAD ONNX is tuned for 16kHz; current SAMPLE_RATE={self.sample_rate}.", "warning")
         self.vad_model_path = os.path.join(config.BASE_DIR, "silero_vad.onnx")
         self.download_vad_if_needed()
         self._running = False
@@ -19,7 +22,17 @@
         # Metering State
         self._metering = False
         self._current_vol = 0.0
+        self._current_speech_prob = 0.0
         self._meter_stream = None
+        self._meter_h = None
+        self._meter_c = None
+
+        # Voice-activation state (cooldown)
+        self._next_allowed_start_time = 0.0
+
+        # Serialize VAD inference across threads (metering vs recording)
+        self._vad_lock = threading.Lock()
+        self._meter_was_running = False
         
         # Force CPU for VAD
         try:
@@ -37,12 +50,26 @@
         """Starts a background thread/stream for volume metering."""
         if self._metering: return
         self._metering = True
-        
+
         def meter_callback(indata, frames, time, status):
             if status:
                 print(status)
             vol = np.sqrt(np.mean(indata**2))
             self._current_vol = vol * 50 # Scale up
+
+            try:
+                # Estimate VAD speech probability for calibration in Settings UI.
+                # Uses a separate Silero state than the recording path.
+                if self._meter_h is None or self._meter_c is None:
+                    self._meter_h = np.zeros((2, 1, 64), dtype=np.float32)
+                    self._meter_c = np.zeros((2, 1, 64), dtype=np.float32)
+
+                chunk = indata.reshape(-1).astype(np.float32)
+                speech_prob, self._meter_h, self._meter_c = self._vad_iterator(chunk, self._meter_h, self._meter_c)
+                self._current_speech_prob = float(speech_prob)
+            except Exception:
+                # Never let UI metering crash audio callback.
+                pass
 
         try:
             device_idx = settings.get("input_device_index")
@@ -52,7 +79,8 @@
                 channels=1,
                 samplerate=self.sample_rate,
                 device=device_idx,
-                blocksize=1024
+                blocksize=512,
+                dtype="float32",
             )
             self._meter_stream.start()
             log("Metering started.", "info")
@@ -68,19 +96,26 @@
             self._meter_stream = None
         self._metering = False
         self._current_vol = 0.0
+        self._current_speech_prob = 0.0
+        self._meter_h = None
+        self._meter_c = None
         log("Metering stopped.", "info")
 
     def get_current_volume(self):
         """Returns the cached volume level (Instant)."""
         return self._current_vol
+
+    def get_current_speech_prob(self):
+        """Returns the cached Silero speech probability [0..1]."""
+        return self._current_speech_prob
     # --------------------------
 
     def download_vad_if_needed(self):
-         if not os.path.exists(self.vad_model_path) or os.path.getsize(self.vad_model_path) < 1000000:
+        if not os.path.exists(self.vad_model_path) or os.path.getsize(self.vad_model_path) < 1000000:
             url = "https://github.com/snakers4/silero-vad/raw/v4.0/files/silero_vad.onnx"
             try:
                 headers = {'User-Agent': 'Mozilla/5.0'}
-                r = requests.get(url, headers=headers, allow_redirects=True)
+                r = requests.get(url, headers=headers, allow_redirects=True, timeout=10)
                 if r.status_code == 200 and len(r.content) > 1000000:
                     with open(self.vad_model_path, 'wb') as f:
                         f.write(r.content)
@@ -97,76 +132,184 @@
             self.vad_session.get_inputs()[2].name: h,
             self.vad_session.get_inputs()[3].name: c
         }
-        ort_outs = self.vad_session.run(None, ort_inputs)
+        with self._vad_lock:
+            ort_outs = self.vad_session.run(None, ort_inputs)
         out, h, c = ort_outs
         return out[0][0], h, c
 
     def stop_recording(self):
         self._running = False
 
+    def _pause_metering_if_needed(self):
+        if self._metering and self._meter_stream:
+            try:
+                self._meter_stream.stop()
+                self._meter_was_running = True
+            except Exception:
+                self._meter_was_running = False
+        else:
+            self._meter_was_running = False
+
+    def _resume_metering_if_needed(self):
+        if self._meter_was_running and self._meter_stream:
+            try:
+                self._meter_stream.start()
+            except Exception:
+                pass
+        self._meter_was_running = False
+
+    @staticmethod
+    def _rms_dbfs(samples: np.ndarray) -> float:
+        # dB relative to full-scale for float audio in [-1..1].
+        rms = float(np.sqrt(np.mean(samples * samples))) if samples.size else 0.0
+        return 20.0 * math.log10(max(rms, 1e-8))
+
     def listen_single_segment(self):
         self._running = True
-        CHUNK_SIZE = 512
-        
-        threshold = settings.get("vad_threshold")
+        CHUNK_SIZE = int(getattr(config, "BLOCK_SIZE", 512))
+        if self.sample_rate == 16000 and CHUNK_SIZE != 512:
+            log(f"Silero VAD expects 512 samples at 16kHz; overriding BLOCK_SIZE={CHUNK_SIZE} -> 512.", "warning")
+            CHUNK_SIZE = 512
+
+        threshold = float(settings.get("vad_threshold"))
         silence_dur = settings.get("silence_duration")
         device_idx = settings.get("input_device_index") 
-        
-        chunks_per_sec = self.sample_rate / CHUNK_SIZE
-        silence_chunks = int(silence_dur * chunks_per_sec)
-        
+
+        start_confirm_ms = int(settings.get("voice_activation_start_confirm_ms"))
+        hangover_ms = int(settings.get("voice_activation_hangover_ms"))
+        cooldown_ms = int(settings.get("voice_activation_cooldown_ms"))
+        pre_roll_ms = int(settings.get("voice_activation_pre_roll_ms"))
+        min_segment_ms = int(settings.get("voice_activation_min_segment_ms"))
+        min_speech_ms = int(settings.get("voice_activation_min_speech_ms"))
+        max_segment_s = float(settings.get("voice_activation_max_segment_s"))
+        start_speech_prob = float(settings.get("voice_activation_start_speech_prob"))
+        stop_speech_prob = float(settings.get("voice_activation_stop_speech_prob"))
+        start_db_margin = float(settings.get("voice_activation_start_db_margin"))
+        stop_db_margin = float(settings.get("voice_activation_stop_db_margin"))
+        noise_update_speech_prob = float(settings.get("voice_activation_noise_update_speech_prob"))
+        noise_ema_alpha = float(settings.get("voice_activation_noise_ema_alpha"))
+
+        # Backwards-compatible: allow the legacy single threshold to still affect gating.
+        start_speech_prob = max(start_speech_prob, threshold)
+        stop_speech_prob = min(stop_speech_prob, start_speech_prob - 0.08) if stop_speech_prob >= start_speech_prob else stop_speech_prob
+
+        chunk_ms = (CHUNK_SIZE / self.sample_rate) * 1000.0
+        start_confirm_chunks = max(1, int(math.ceil(start_confirm_ms / chunk_ms)))
+
         h = np.zeros((2, 1, 64), dtype=np.float32)
         c = np.zeros((2, 1, 64), dtype=np.float32)
-        
+
         triggered = False
         temp_buffer = []
         ring_buffer = [] 
-        ring_buffer_size = 30
-        silence_counter = 0
-        
-        log(f"Listening loop started (Thresh: {threshold:.2f})", "debug")
-        print(f"Listening (VAD: {threshold})...")
-        
+        ring_buffer_size = max(1, int(math.ceil(pre_roll_ms / chunk_ms)))
+
+        # Adaptive noise floor (dBFS)
+        # Updates only while ARMED (not recording) and not in a start-candidate streak.
+        noise_floor_db = -55.0
+        noise_floor_db = float(max(-80.0, min(-20.0, noise_floor_db)))
+        start_candidate_count = 0
+        speech_ms = 0.0
+        trigger_start_time = 0.0
+        last_speech_time = 0.0
+        max_speech_prob = 0.0
+        max_rms_db = -120.0
+
+        now = time.time()
+        if now < self._next_allowed_start_time:
+            time.sleep(max(0.0, self._next_allowed_start_time - now))
+
         try:
-            with sd.InputStream(samplerate=self.sample_rate, device=device_idx, channels=1, blocksize=CHUNK_SIZE) as stream:
+            self._pause_metering_if_needed()
+            with sd.InputStream(
+                samplerate=self.sample_rate,
+                device=device_idx,
+                channels=1,
+                blocksize=CHUNK_SIZE,
+                dtype="float32",
+            ) as stream:
                 while self._running:
                     data, overflowed = stream.read(CHUNK_SIZE)
                     data = data.flatten()
-                    
+
                     speech_prob, h, c = self._vad_iterator(data, h, c)
-                    
+                    rms_db = self._rms_dbfs(data)
+                    max_speech_prob = max(max_speech_prob, float(speech_prob))
+                    max_rms_db = max(max_rms_db, float(rms_db))
+
                     if not triggered:
                         ring_buffer.append(data)
                         if len(ring_buffer) > ring_buffer_size:
                             ring_buffer.pop(0)
-                        
-                        if speech_prob > threshold:
-                            print(f"Voice: {speech_prob:.2f}")
+
+                        # Update baseline noise floor only when we're not in speech and not already trending toward a trigger.
+                        if start_candidate_count == 0 and speech_prob <= noise_update_speech_prob:
+                            noise_floor_db = (1.0 - noise_ema_alpha) * noise_floor_db + noise_ema_alpha * rms_db
+                            noise_floor_db = float(max(-80.0, min(-20.0, noise_floor_db)))
+
+                        # Start gate: require sustained speech probability AND energy above baseline.
+                        start_gate = (speech_prob >= start_speech_prob) and (rms_db >= (noise_floor_db + start_db_margin))
+                        if start_gate:
+                            start_candidate_count += 1
+                        else:
+                            start_candidate_count = 0
+
+                        if start_candidate_count >= start_confirm_chunks:
                             triggered = True
+                            trigger_start_time = time.time()
+                            last_speech_time = trigger_start_time
                             temp_buffer.extend(ring_buffer)
-                            temp_buffer.append(data)
-                            silence_counter = 0
+                            speech_ms = start_confirm_chunks * chunk_ms
                     else:
                         temp_buffer.append(data)
-                        if speech_prob < threshold:
-                            silence_counter += 1
-                        else:
-                            silence_counter = 0
-                            
-                        if silence_counter > silence_chunks:
-                            print("Silence.")
+
+                        # Track "speech present" with hysteresis + energy margin.
+                        speech_present = (speech_prob >= stop_speech_prob) or (rms_db >= (noise_floor_db + stop_db_margin))
+                        if speech_present:
+                            last_speech_time = time.time()
+                            speech_ms += chunk_ms
+                        # While recording, do NOT update baseline (prevents music from "teaching" the baseline mid-utterance).
+
+                        # Stop gate: end after sustained silence + hangover.
+                        effective_silence_s = float(silence_dur) + (hangover_ms / 1000.0)
+                        if (time.time() - last_speech_time) >= effective_silence_s:
                             break
-                            
+
+                        # Safety: prevent infinite segments on continuous background noise.
+                        if (time.time() - trigger_start_time) >= max_segment_s:
+                            log("Max segment duration reached; cutting segment.", "warning")
+                            break
+
             if not self._running:
                 log("Recording interrupted.", "info")
                 return np.array([], dtype=np.float32)
-                
-            return np.concatenate(temp_buffer)
+
+            # Reject very short or likely-false triggers.
+            total_ms = (time.time() - trigger_start_time) * 1000.0 if triggered else 0.0
+            if (not triggered) or (total_ms < min_segment_ms) or (speech_ms < min_speech_ms):
+                self._next_allowed_start_time = time.time() + (cooldown_ms / 1000.0)
+                return np.array([], dtype=np.float32)
+
+            self._next_allowed_start_time = time.time() + (cooldown_ms / 1000.0)
+            audio = np.concatenate(temp_buffer).astype(np.float32)
+
+            if settings.get("voice_activation_debug"):
+                dur_s = float(len(audio) / self.sample_rate)
+                log(
+                    f"VAD segment: dur={dur_s:.2f}s max_p={max_speech_prob:.2f} "
+                    f"max_rms_db={max_rms_db:.1f} noise_db={noise_floor_db:.1f} "
+                    f"speech_ms={speech_ms:.0f}",
+                    "info",
+                )
+
+            return audio
         except Exception as e:
             log(f"Recording Exception: {e}", "error")
             print(f"Recording Error: {e}")
             time.sleep(1)
             return np.array([], dtype=np.float32)
+        finally:
+            self._resume_metering_if_needed()
 
 if __name__ == "__main__":
     eng = AudioEngine()
--- a/core/transcriber.py
+++ b/core/transcriber.py
@@ -2,18 +2,189 @@
 import config
 import os
 import time
+import inspect
+from core.settings import manager as settings
+from core.logger import log
 
 class Transcriber:
     def __init__(self):
         print(f"Loading Whisper Model: {config.WHISPER_MODEL_SIZE} on {config.DEVICE}...")
         start = time.time()
-        self.model = WhisperModel(
-            config.WHISPER_MODEL_SIZE, 
-            device=config.DEVICE, 
-            compute_type=config.COMPUTE_TYPE,
-            download_root=config.MODELS_DIR
+        self._compute_type_effective = config.COMPUTE_TYPE
+        try:
+            self.model = WhisperModel(
+                config.WHISPER_MODEL_SIZE,
+                device=config.DEVICE,
+                compute_type=config.COMPUTE_TYPE,
+                download_root=config.MODELS_DIR,
+            )
+        except Exception as e:
+            # Explicit fallback for reliability (VRAM/driver issues): retry with int8.
+            log(f"Whisper model load failed with compute_type={config.COMPUTE_TYPE}: {e}", "warning")
+            self._compute_type_effective = "int8"
+            self.model = WhisperModel(
+                config.WHISPER_MODEL_SIZE,
+                device=config.DEVICE,
+                compute_type="int8",
+                download_root=config.MODELS_DIR,
+            )
+        print(f"Model loaded in {time.time() - start:.2f}s (compute_type={self._compute_type_effective})")
+
+        self._sticky_language = None
+        self._sticky_set_time = 0.0
+        self._last_redetect_time = 0.0
+        self._warned_unsupported_args = set()
+        self._transcribe_sig = inspect.signature(WhisperModel.transcribe)
+
+        # Last-result metadata for downstream policy (LLM/refuse/etc.)
+        self.last_confidence = "unknown"  # high|medium|low|silence|unknown
+        self.last_stats = {}
+
+    def _choose_language(self, requested_language: str | None) -> str | None:
+        if requested_language:
+            return requested_language
+
+        if settings.get("transcription_language") != "auto":
+            return settings.get("transcription_language")
+
+        if not settings.get("sticky_language_enabled"):
+            return None
+
+        ttl_s = float(settings.get("sticky_language_ttl_s"))
+        redetect_interval_s = float(settings.get("sticky_language_redetect_interval_s"))
+        now = time.time()
+
+        # Periodically allow re-detection to enable deliberate language switching.
+        if (now - self._last_redetect_time) >= redetect_interval_s:
+            self._last_redetect_time = now
+            return None
+
+        if self._sticky_language and (now - self._sticky_set_time) <= ttl_s:
+            return self._sticky_language
+
+        return None
+
+    def _validate_and_build_decode_args(self, noisy: bool) -> dict:
+        """
+        Build a dict of WhisperModel.transcribe kwargs from Settings.
+        Enforces: unknown/unsupported args are not silently applied.
+        """
+        def clamp_int(name: str, value, lo: int, hi: int, default: int) -> int:
+            try:
+                v = int(value)
+            except Exception:
+                log(f"Invalid {name}={value!r}; using {default}.", "warning")
+                return default
+            if v < lo or v > hi:
+                log(f"Out-of-range {name}={v}; clamping to [{lo},{hi}].", "warning")
+                v = max(lo, min(hi, v))
+            return v
+
+        def clamp_float(name: str, value, lo: float, hi: float, default: float) -> float:
+            try:
+                v = float(value)
+            except Exception:
+                log(f"Invalid {name}={value!r}; using {default}.", "warning")
+                return default
+            if v < lo or v > hi:
+                log(f"Out-of-range {name}={v}; clamping to [{lo},{hi}].", "warning")
+                v = max(lo, min(hi, v))
+            return float(v)
+
+        if noisy:
+            beam_size = clamp_int("decode_noisy_beam_size", settings.get("decode_noisy_beam_size"), 1, 20, 10)
+            best_of = clamp_int("decode_noisy_best_of", settings.get("decode_noisy_best_of"), 1, 10, 1)
+            condition_on_previous_text = bool(settings.get("decode_noisy_condition_on_previous_text"))
+        else:
+            beam_size = clamp_int("decode_beam_size", settings.get("decode_beam_size"), 1, 20, 8)
+            best_of = clamp_int("decode_best_of", settings.get("decode_best_of"), 1, 10, 1)
+            condition_on_previous_text = bool(settings.get("decode_condition_on_previous_text"))
+
+        temperature = clamp_float("decode_temperature", settings.get("decode_temperature"), 0.0, 1.0, 0.0)
+        patience = clamp_float("decode_patience", settings.get("decode_patience"), 0.1, 2.5, 1.0)
+        length_penalty = clamp_float("decode_length_penalty", settings.get("decode_length_penalty"), 0.5, 1.5, 1.0)
+        repetition_penalty = clamp_float("decode_repetition_penalty", settings.get("decode_repetition_penalty"), 1.0, 1.5, 1.08)
+        no_repeat_ngram_size = clamp_int("decode_no_repeat_ngram_size", settings.get("decode_no_repeat_ngram_size"), 0, 10, 0)
+        no_speech_threshold = clamp_float("decode_no_speech_threshold", settings.get("decode_no_speech_threshold"), 0.0, 1.0, 0.6)
+        log_prob_threshold = clamp_float("decode_log_prob_threshold", settings.get("decode_log_prob_threshold"), -5.0, 0.0, -1.0)
+        compression_ratio_threshold = clamp_float("decode_compression_ratio_threshold", settings.get("decode_compression_ratio_threshold"), 1.5, 3.5, 2.35)
+        language_detection_threshold = clamp_float("language_detection_threshold", settings.get("language_detection_threshold"), 0.0, 1.0, 0.6)
+        language_detection_segments = clamp_int("language_detection_segments", settings.get("language_detection_segments"), 1, 10, 2)
+
+        # Preferred args set (hardcoded whitelist) -> strict validation vs installed faster-whisper.
+        desired = {
+            "beam_size": beam_size,
+            "best_of": best_of,
+            "patience": patience,
+            "length_penalty": length_penalty,
+            "repetition_penalty": repetition_penalty,
+            "no_repeat_ngram_size": no_repeat_ngram_size,
+            "temperature": temperature,
+            "condition_on_previous_text": condition_on_previous_text,
+            "no_speech_threshold": no_speech_threshold,
+            "log_prob_threshold": log_prob_threshold,
+            "compression_ratio_threshold": compression_ratio_threshold,
+            "language_detection_threshold": language_detection_threshold,
+            "language_detection_segments": language_detection_segments,
+
+            # Always fixed for this app (audio already segmented by VAD).
+            "vad_filter": False,
+            "word_timestamps": False,
+        }
+
+        supported = set(self._transcribe_sig.parameters.keys())
+        effective = {}
+        unsupported = sorted([k for k in desired.keys() if k not in supported])
+        if unsupported:
+            for k in unsupported:
+                if k not in self._warned_unsupported_args:
+                    log(f"Unsupported faster-whisper transcribe arg ignored: {k}", "warning")
+                    self._warned_unsupported_args.add(k)
+
+        for k, v in desired.items():
+            if k in supported:
+                effective[k] = v
+        return effective
+
+    def _classify_confidence(self, segments: list, text: str) -> tuple[str, dict]:
+        if not segments or not text:
+            return "silence", {"reason": "empty"}
+
+        avg_no_speech = sum(float(s.no_speech_prob) for s in segments) / max(1, len(segments))
+        avg_logprob = sum(float(s.avg_logprob) for s in segments) / max(1, len(segments))
+        avg_compression = sum(float(s.compression_ratio) for s in segments) / max(1, len(segments))
+
+        stats = {
+            "avg_no_speech_prob": float(avg_no_speech),
+            "avg_logprob": float(avg_logprob),
+            "avg_compression_ratio": float(avg_compression),
+            "segments": int(len(segments)),
+            "chars": int(len(text)),
+        }
+
+        # Hard reject: very likely silence + low logprob.
+        reject_no_speech_prob = float(settings.get("reject_no_speech_prob"))
+        reject_avg_logprob = float(settings.get("reject_avg_logprob"))
+        if avg_no_speech >= reject_no_speech_prob and avg_logprob <= reject_avg_logprob:
+            return "silence", {**stats, "reason": "no_speech"}
+
+        high = (
+            avg_logprob >= float(settings.get("conf_high_min_avg_logprob"))
+            and avg_no_speech <= float(settings.get("conf_high_max_avg_no_speech_prob"))
+            and avg_compression <= float(settings.get("conf_high_max_avg_compression_ratio"))
         )
-        print(f"Model loaded in {time.time() - start:.2f}s")
+        if high:
+            return "high", stats
+
+        medium = (
+            avg_logprob >= float(settings.get("conf_med_min_avg_logprob"))
+            and avg_no_speech <= float(settings.get("conf_med_max_avg_no_speech_prob"))
+            and avg_compression <= float(settings.get("conf_med_max_avg_compression_ratio"))
+        )
+        if medium:
+            return "medium", stats
+
+        return "low", stats
 
     def transcribe(self, audio_data, language=None):
         """
@@ -23,12 +194,82 @@
         if audio_data.dtype != "float32":
             audio_data = audio_data.astype("float32")
 
-        # Use passed language (or None for auto)
-        segments,info = self.model.transcribe(audio_data, beam_size=5, language=language, task="transcribe")
-        
-        # Collect all text
-        text = " ".join([segment.text for segment in segments])
-        return text.strip()
+        chosen_language = self._choose_language(language)
+
+        base_args = self._validate_and_build_decode_args(noisy=False)
+        segments, info = self.model.transcribe(
+            audio_data,
+            task="transcribe",
+            language=chosen_language,
+            **base_args,
+        )
+
+        segments = list(segments)
+        text = " ".join([segment.text for segment in segments]).strip()
+
+        confidence, stats = self._classify_confidence(segments, text)
+        self.last_confidence = confidence
+        self.last_stats = stats
+
+        min_chars = int(settings.get("reject_min_chars"))
+        if len(text) < min_chars:
+            self.last_confidence = "silence"
+            self.last_stats = {**stats, "reason": "too_short"}
+            return ""
+
+        # Optional quality-first second pass when the first decode looks noisy.
+        if confidence == "low" and settings.get("decode_enable_noisy_second_pass"):
+            noisy_args = self._validate_and_build_decode_args(noisy=True)
+            segments2, info2 = self.model.transcribe(
+                audio_data,
+                task="transcribe",
+                language=chosen_language,
+                **noisy_args,
+            )
+            segments2 = list(segments2)
+            text2 = " ".join([s.text for s in segments2]).strip()
+            conf2, stats2 = self._classify_confidence(segments2, text2)
+
+            # Choose the higher-confidence result; tie-breaker by avg_logprob.
+            rank = {"high": 3, "medium": 2, "low": 1, "silence": 0, "unknown": 0}
+            choose_second = False
+            if rank.get(conf2, 0) > rank.get(confidence, 0):
+                choose_second = True
+            elif conf2 == confidence:
+                if stats2.get("avg_logprob", -9) > stats.get("avg_logprob", -9):
+                    choose_second = True
+
+            if choose_second:
+                segments, text, confidence, stats = segments2, text2, conf2, stats2
+                info = info2
+                self.last_confidence = confidence
+                self.last_stats = {**stats, "pass": "noisy_second"}
+            else:
+                self.last_stats = {**stats, "pass": "base"}
+
+        if self.last_confidence in {"silence", "low"}:
+            # Quality > latency: do not inject low-confidence text.
+            return ""
+
+        # Update sticky language only when auto-detect was used.
+        if chosen_language is None and settings.get("sticky_language_enabled"):
+            min_prob = float(settings.get("sticky_language_min_prob"))
+            if getattr(info, "language_probability", 0.0) >= min_prob and getattr(info, "language", None):
+                self._sticky_language = info.language
+                self._sticky_set_time = time.time()
+
+        return text
+
+    def dump_effective_decode_args(self) -> dict:
+        """
+        Returns the actual kwargs we will pass to WhisperModel.transcribe for both base/noisy.
+        Useful for debugging and for detecting API mismatches.
+        """
+        return {
+            "base": self._validate_and_build_decode_args(noisy=False),
+            "noisy": self._validate_and_build_decode_args(noisy=True),
+            "compute_type_effective": self._compute_type_effective,
+        }
 
 if __name__ == "__main__":
     t = Transcriber()
--- a/core/intelligence.py
+++ b/core/intelligence.py
@@ -1,72 +1,152 @@
+import re
 import requests
+
 import config
-import json
+from core.logger import log
+from core.settings import manager as settings
+
 
 class IntelligenceEngine:
     def __init__(self):
         self.url = config.OLLAMA_URL
         self.model = config.OLLAMA_MODEL
         print(f"Intelligence Engine connected to {self.model} at {self.url}")
-        
-    def refine_text(self, text):
+
+    @staticmethod
+    def _is_code_like(text: str) -> bool:
+        t = text.strip()
+        if not t:
+            return True
+
+        # Multi-line output is overwhelmingly terminal output / code / logs.
+        if "\n" in t or "\r" in t:
+            return True
+
+        # High-signal CLI/code markers.
+        code_markers = [
+            " --",
+            "--",
+            " -",
+            " /",
+            "\\",
+            "/",
+            "::",
+            "://",
+            "@",
+            "$",
+            "|",
+            "&&",
+            "||",
+            ";",
+            ">>",
+            "<<",
+            "{",
+            "}",
+            "[",
+            "]",
+            "(",
+            ")",
+            "<",
+            ">",
+            "=>",
+            "==",
+            "!=",
+            ":\\",
+            "~/",
+            "#",
+            "`",
+        ]
+        if any(m in t for m in code_markers):
+            return True
+
+        if re.search(r"\b([A-Za-z]:\\|/home/|/usr/|/etc/|~\/)\b", t):
+            return True
+        if re.search(r"(^|\s)--?[A-Za-z0-9][A-Za-z0-9_-]*", t):
+            return True
+        if re.search(r"\b(sudo|ssh|scp|rsync|tmux|vim|nvim|nano|git|pip|conda|docker|kubectl|helm)\b", t):
+            return True
+        if re.search(r"(^|\s)[A-Za-z_][A-Za-z0-9_]*=", t):
+            return True
+
+        # High symbol density => likely technical.
+        symbol_count = sum(1 for ch in t if not (ch.isalpha() or ch.isspace()))
+        if symbol_count / max(1, len(t)) >= 0.18:
+            return True
+
+        return False
+
+    def _should_refine(self, text: str) -> bool:
         if not text or len(text.strip()) < 2:
+            return False
+        if len(text) > int(settings.get("llm_refine_max_chars")):
+            return False
+        if settings.get("llm_refine_skip_code_like") and self._is_code_like(text):
+            return False
+        return True
+
+    def refine_text(self, text: str) -> str:
+        if not self._should_refine(text):
             return text
 
-        # System prompt optimized with 2026 best practices
-        system_prompt = (
-            "You are a minimal grammar correction assistant.\n\n"
-            "## TASK\n"
-            "Fix ONLY spelling errors and verb conjugation mistakes.\n"
-            "Make MINIMAL changes - preserve the user's exact wording, style, and sentence structure.\n\n"
-
-            "## CRITICAL RULES\n"
-            "1. Fix spelling mistakes (écrir → écrire, brokan → broken)\n"
-            "2. Fix verb conjugations (salute → salue, march → marche)\n"
-            "3. Fix obvious typos caused by thick accent (ze → the)\n"
-            "4. Remove filler words ONLY: euh, um, ah, like\n"
-            "5. PRESERVE the exact same words (do NOT use synonyms)\n"
-            "6. PRESERVE the sentence structure (do NOT reorganize)\n"
-            "7. PRESERVE punctuation (do NOT add commas/periods unless critical)\n"
-            "8. Keep the SAME language (French stays French, English stays English)\n\n"
-
-            "## EXAMPLES\n"
-            "Input: 'bonjour le docker il march pas'\n"
-            "Output: 'bonjour le docker il marche pas'\n\n"
-
-            "Input: 'je suis en train de t'écrir et cela fonctionne'\n"
-            "Output: 'je suis en train de t'écrire et cela fonctionne'\n\n"
-
-            "Input: 'hello ze code is brokan'\n"
-            "Output: 'hello the code is broken'\n\n"
-
-            "Input: 'euh je salute mon ami from Montréal'\n"
-            "Output: 'je salue mon ami from Montréal'\n\n"
-
-            "## OUTPUT FORMAT\n"
-            "Return ONLY the corrected text. No explanations, no quotes, no comments."
+        prompt = (
+            "You are a STRICT copy editor for dictated prose.\n"
+            "Return ONLY the corrected text. No quotes, no explanations.\n\n"
+            "Rules:\n"
+            "1) Preserve meaning exactly. Do NOT paraphrase.\n"
+            "2) Do NOT translate or change language.\n"
+            "3) Fix only: obvious spelling, obvious homophone mistakes, basic punctuation, capitalization.\n"
+            "4) Remove only these fillers when standalone words: euh, um, uh, ah, like.\n"
+            "5) Preserve whitespace (including leading/trailing spaces).\n"
+            "6) If unsure, output the input unchanged.\n\n"
+            "Input:\n"
+            "<<<\n"
+            f"{text}\n"
+            ">>>\n"
+            "Corrected:\n"
         )
 
         payload = {
             "model": config.OLLAMA_MODEL,
-            "prompt": f"{system_prompt}\nInput: '{text}'\nOutput:",
+            "prompt": prompt,
             "stream": False,
             "options": {
-                "temperature": 0.0 # STRICT. No creativity. Deterministic.
-            }
+                "temperature": 0.0,
+            },
         }
 
         try:
-            response = requests.post(self.url, json=payload)
+            response = requests.post(
+                self.url,
+                json=payload,
+                timeout=float(settings.get("ollama_timeout_s")),
+            )
             response.raise_for_status()
             result = response.json()
-            corrected = result.get("response", "").strip()
-            # Remove any wrapping quotes if mistakenly added by LLM
+            corrected = (result.get("response", "") or "").strip()
+
             if corrected.startswith('"') and corrected.endswith('"'):
                 corrected = corrected[1:-1]
+
+            if not corrected:
+                return text
+
+            # Safety: if the model output diverges wildly, skip refinement.
+            if abs(len(corrected) - len(text)) > max(80, int(len(text) * 0.6)):
+                log("LLM output length diverged; skipping refinement.", "warning")
+                return text
+
+            # Safety: preserve any CLI-ish "critical tokens" if present.
+            critical = re.findall(r"(--?[A-Za-z0-9][A-Za-z0-9_-]*|[A-Za-z]:\\\\[^\\s]+|/[^\\s]+)", text)
+            for token in critical:
+                if token and token not in corrected:
+                    log("LLM output dropped a critical token; skipping refinement.", "warning")
+                    return text
+
             return corrected
         except Exception as e:
-            print(f"Ollama Error: {e}")
-            return text # Fallback to original
+            log(f"Ollama Error: {e}", "warning")
+            return text
+
 
 if __name__ == "__main__":
     eng = IntelligenceEngine()
--- a/core/injector.py
+++ b/core/injector.py
@@ -1,52 +1,422 @@
 import time
 import sys
-import pyperclip
+import os
+import ctypes
+from ctypes import wintypes
 from pynput.keyboard import Controller, Key
+from core.settings import manager as settings
+from core.logger import log
 
 class Injector:
     def __init__(self):
         self.keyboard = Controller()
+        self._terminal_processes = set()
+        self._paste_hotkey_order = []
+        self._refresh_config()
+
+    def _refresh_config(self):
+        processes = settings.get("terminal_processes")
+        if isinstance(processes, list) and processes:
+            self._terminal_processes = {str(p).lower() for p in processes if str(p).strip()}
+        else:
+            self._terminal_processes = {"windowsterminal.exe", "wt.exe", "conhost.exe"}
+
+        order = settings.get("paste_hotkey_order")
+        if isinstance(order, list) and order:
+            self._paste_hotkey_order = [str(x).lower() for x in order if str(x).strip()]
+        else:
+            self._paste_hotkey_order = ["ctrl+shift+v", "shift+insert", "ctrl+v"]
+
+    @staticmethod
+    def _get_foreground_process_name() -> str | None:
+        try:
+            user32 = ctypes.WinDLL("user32", use_last_error=True)
+            kernel32 = ctypes.WinDLL("kernel32", use_last_error=True)
+
+            GetForegroundWindow = user32.GetForegroundWindow
+            GetForegroundWindow.restype = wintypes.HWND
+
+            GetWindowThreadProcessId = user32.GetWindowThreadProcessId
+            GetWindowThreadProcessId.argtypes = [wintypes.HWND, ctypes.POINTER(wintypes.DWORD)]
+            GetWindowThreadProcessId.restype = wintypes.DWORD
+
+            QueryFullProcessImageNameW = kernel32.QueryFullProcessImageNameW
+            QueryFullProcessImageNameW.argtypes = [wintypes.HANDLE, wintypes.DWORD, wintypes.LPWSTR, ctypes.POINTER(wintypes.DWORD)]
+            QueryFullProcessImageNameW.restype = wintypes.BOOL
+
+            OpenProcess = kernel32.OpenProcess
+            OpenProcess.argtypes = [wintypes.DWORD, wintypes.BOOL, wintypes.DWORD]
+            OpenProcess.restype = wintypes.HANDLE
+
+            CloseHandle = kernel32.CloseHandle
+            CloseHandle.argtypes = [wintypes.HANDLE]
+            CloseHandle.restype = wintypes.BOOL
+
+            hwnd = GetForegroundWindow()
+            if not hwnd:
+                return None
+
+            pid = wintypes.DWORD(0)
+            GetWindowThreadProcessId(hwnd, ctypes.byref(pid))
+            if not pid.value:
+                return None
+
+            PROCESS_QUERY_LIMITED_INFORMATION = 0x1000
+            hproc = OpenProcess(PROCESS_QUERY_LIMITED_INFORMATION, False, pid.value)
+            if not hproc:
+                return None
+
+            try:
+                buf_len = wintypes.DWORD(260)
+                buf = ctypes.create_unicode_buffer(buf_len.value)
+                if not QueryFullProcessImageNameW(hproc, 0, buf, ctypes.byref(buf_len)):
+                    return None
+                exe = os.path.basename(buf.value).lower()
+                return exe or None
+            finally:
+                CloseHandle(hproc)
+        except Exception:
+            return None
+
+    def _is_terminal(self, process_name: str | None) -> bool:
+        if not process_name:
+            return False
+        return process_name.lower() in self._terminal_processes
+
+    def _press_combo(self, combo: str) -> bool:
+        """
+        combo examples: 'ctrl+v', 'ctrl+shift+v', 'shift+insert'
+        Returns True if we attempted to send it without throwing.
+        """
+        try:
+            parts = [p.strip().lower() for p in combo.split("+") if p.strip()]
+            if not parts:
+                return False
+
+            mods = []
+            key = parts[-1]
+            for p in parts[:-1]:
+                if p in {"ctrl", "control"}:
+                    mods.append(Key.ctrl)
+                elif p == "shift":
+                    mods.append(Key.shift)
+                elif p == "alt":
+                    mods.append(Key.alt)
+
+            def press_key(k: str):
+                if k == "insert":
+                    self.keyboard.press(Key.insert)
+                    self.keyboard.release(Key.insert)
+                else:
+                    self.keyboard.type(k)
+
+            ctx = None
+            # Nest pressed() contexts for modifiers.
+            if mods:
+                ctx = self.keyboard.pressed(mods[0])
+                ctx.__enter__()
+                entered = [ctx]
+                for m in mods[1:]:
+                    c = self.keyboard.pressed(m)
+                    c.__enter__()
+                    entered.append(c)
+                try:
+                    press_key(key)
+                finally:
+                    for c in reversed(entered):
+                        c.__exit__(None, None, None)
+            else:
+                press_key(key)
+            return True
+        except Exception:
+            return False
+
+    def _send_paste_hotkey(self, is_terminal: bool):
+        if not is_terminal:
+            self._press_combo("ctrl+v")
+            return
+
+        # Configurable ordering; we only fall back if sending the combo throws.
+        for combo in self._paste_hotkey_order:
+            if self._press_combo(combo):
+                return
+        # Last resort
+        self._press_combo("ctrl+v")
+
+    # --- Clipboard (Win32) ---
+    _CF_UNICODETEXT = 13
+    _GMEM_MOVEABLE = 0x0002
+
+    def _clipboard_open_retry(self) -> bool:
+        tries = int(settings.get("inject_clipboard_retry_count"))
+        backoff_ms = int(settings.get("inject_clipboard_retry_backoff_ms"))
+        delay = max(0.0, backoff_ms / 1000.0)
+
+        user32 = ctypes.WinDLL("user32", use_last_error=True)
+        OpenClipboard = user32.OpenClipboard
+        OpenClipboard.argtypes = [wintypes.HWND]
+        OpenClipboard.restype = wintypes.BOOL
+
+        for _ in range(max(1, tries)):
+            if OpenClipboard(None):
+                return True
+            time.sleep(delay)
+            delay = min(0.25, delay * 2.0 if delay else 0.02)
+        return False
+
+    @staticmethod
+    def _clipboard_close():
+        user32 = ctypes.WinDLL("user32", use_last_error=True)
+        user32.CloseClipboard()
+
+    @staticmethod
+    def _clipboard_get_sequence() -> int:
+        try:
+            user32 = ctypes.WinDLL("user32", use_last_error=True)
+            GetClipboardSequenceNumber = user32.GetClipboardSequenceNumber
+            GetClipboardSequenceNumber.restype = wintypes.DWORD
+            return int(GetClipboardSequenceNumber())
+        except Exception:
+            return -1
+
+    def _clipboard_get_unicode_text_unsafe(self) -> str | None:
+        user32 = ctypes.WinDLL("user32", use_last_error=True)
+        kernel32 = ctypes.WinDLL("kernel32", use_last_error=True)
+
+        GetClipboardData = user32.GetClipboardData
+        GetClipboardData.argtypes = [wintypes.UINT]
+        GetClipboardData.restype = wintypes.HANDLE
+
+        GlobalLock = kernel32.GlobalLock
+        GlobalLock.argtypes = [wintypes.HGLOBAL]
+        GlobalLock.restype = wintypes.LPVOID
+
+        GlobalUnlock = kernel32.GlobalUnlock
+        GlobalUnlock.argtypes = [wintypes.HGLOBAL]
+        GlobalUnlock.restype = wintypes.BOOL
+
+        h = GetClipboardData(self._CF_UNICODETEXT)
+        if not h:
+            return None
+        p = GlobalLock(h)
+        if not p:
+            return None
+        try:
+            return ctypes.wstring_at(p)
+        finally:
+            GlobalUnlock(h)
+
+    def _clipboard_snapshot_unsafe(self) -> tuple[int, bool, list[tuple[int, bytes]]]:
+        """
+        Returns (sequence_number, formats_bytes) for all GlobalAlloc-able formats.
+        Non-global-handle formats will be skipped (best-effort).
+        """
+        user32 = ctypes.WinDLL("user32", use_last_error=True)
+        kernel32 = ctypes.WinDLL("kernel32", use_last_error=True)
+
+        EnumClipboardFormats = user32.EnumClipboardFormats
+        EnumClipboardFormats.argtypes = [wintypes.UINT]
+        EnumClipboardFormats.restype = wintypes.UINT
+
+        GetClipboardData = user32.GetClipboardData
+        GetClipboardData.argtypes = [wintypes.UINT]
+        GetClipboardData.restype = wintypes.HANDLE
+
+        GlobalSize = kernel32.GlobalSize
+        GlobalSize.argtypes = [wintypes.HGLOBAL]
+        GlobalSize.restype = ctypes.c_size_t
+
+        GlobalLock = kernel32.GlobalLock
+        GlobalLock.argtypes = [wintypes.HGLOBAL]
+        GlobalLock.restype = wintypes.LPVOID
+
+        GlobalUnlock = kernel32.GlobalUnlock
+        GlobalUnlock.argtypes = [wintypes.HGLOBAL]
+        GlobalUnlock.restype = wintypes.BOOL
+
+        seq = self._clipboard_get_sequence()
+        out: list[tuple[int, bytes]] = []
+        had_any = False
+
+        fmt = 0
+        while True:
+            fmt = int(EnumClipboardFormats(fmt))
+            if fmt == 0:
+                break
+            had_any = True
+            h = GetClipboardData(fmt)
+            if not h:
+                continue
+            try:
+                size = int(GlobalSize(h))
+                if size <= 0:
+                    continue
+                p = GlobalLock(h)
+                if not p:
+                    continue
+                try:
+                    data = ctypes.string_at(p, size)
+                    out.append((fmt, data))
+                finally:
+                    GlobalUnlock(h)
+            except Exception:
+                # Likely a non-global handle format (e.g., CF_BITMAP); skip.
+                continue
+
+        return seq, had_any, out
+
+    def _clipboard_set_formats_unsafe(self, formats: list[tuple[int, bytes]]) -> bool:
+        user32 = ctypes.WinDLL("user32", use_last_error=True)
+        kernel32 = ctypes.WinDLL("kernel32", use_last_error=True)
+
+        EmptyClipboard = user32.EmptyClipboard
+        EmptyClipboard.restype = wintypes.BOOL
+
+        SetClipboardData = user32.SetClipboardData
+        SetClipboardData.argtypes = [wintypes.UINT, wintypes.HANDLE]
+        SetClipboardData.restype = wintypes.HANDLE
+
+        GlobalAlloc = kernel32.GlobalAlloc
+        GlobalAlloc.argtypes = [wintypes.UINT, ctypes.c_size_t]
+        GlobalAlloc.restype = wintypes.HGLOBAL
+
+        GlobalLock = kernel32.GlobalLock
+        GlobalLock.argtypes = [wintypes.HGLOBAL]
+        GlobalLock.restype = wintypes.LPVOID
+
+        GlobalUnlock = kernel32.GlobalUnlock
+        GlobalUnlock.argtypes = [wintypes.HGLOBAL]
+        GlobalUnlock.restype = wintypes.BOOL
+
+        if not EmptyClipboard():
+            return False
+
+        # Restore in stable order.
+        for fmt, data in sorted(formats, key=lambda x: x[0]):
+            try:
+                h = GlobalAlloc(self._GMEM_MOVEABLE, len(data))
+                if not h:
+                    continue
+                p = GlobalLock(h)
+                if not p:
+                    continue
+                try:
+                    ctypes.memmove(p, data, len(data))
+                finally:
+                    GlobalUnlock(h)
+                if not SetClipboardData(int(fmt), h):
+                    # If SetClipboardData fails, the system does not own h; leak avoidance is non-trivial here.
+                    continue
+            except Exception:
+                continue
+        return True
+
+    def _clipboard_set_unicode_text_unsafe(self, text: str) -> bool:
+        user32 = ctypes.WinDLL("user32", use_last_error=True)
+        kernel32 = ctypes.WinDLL("kernel32", use_last_error=True)
+
+        EmptyClipboard = user32.EmptyClipboard
+        EmptyClipboard.restype = wintypes.BOOL
+
+        SetClipboardData = user32.SetClipboardData
+        SetClipboardData.argtypes = [wintypes.UINT, wintypes.HANDLE]
+        SetClipboardData.restype = wintypes.HANDLE
+
+        GlobalAlloc = kernel32.GlobalAlloc
+        GlobalAlloc.argtypes = [wintypes.UINT, ctypes.c_size_t]
+        GlobalAlloc.restype = wintypes.HGLOBAL
+
+        GlobalLock = kernel32.GlobalLock
+        GlobalLock.argtypes = [wintypes.HGLOBAL]
+        GlobalLock.restype = wintypes.LPVOID
+
+        GlobalUnlock = kernel32.GlobalUnlock
+        GlobalUnlock.argtypes = [wintypes.HGLOBAL]
+        GlobalUnlock.restype = wintypes.BOOL
+
+        if not EmptyClipboard():
+            return False
+
+        # Windows expects UTF-16LE including null terminator.
+        raw = (text + "\x00").encode("utf-16le")
+        h = GlobalAlloc(self._GMEM_MOVEABLE, len(raw))
+        if not h:
+            return False
+        p = GlobalLock(h)
+        if not p:
+            return False
+        try:
+            ctypes.memmove(p, raw, len(raw))
+        finally:
+            GlobalUnlock(h)
+        return bool(SetClipboardData(self._CF_UNICODETEXT, h))
+
+    def _paste_via_clipboard(self, text: str, is_terminal: bool):
+        clipboard_settle_ms = int(settings.get("inject_clipboard_settle_ms"))
+        restore_delay_ms = int(settings.get("inject_clipboard_restore_delay_ms"))
+
+        if not self._clipboard_open_retry():
+            raise RuntimeError("clipboard_busy_open")
+        try:
+            before_seq, had_any, snapshot = self._clipboard_snapshot_unsafe()
+            if had_any and not snapshot:
+                raise RuntimeError("clipboard_unbackupable_formats")
+            if not self._clipboard_set_unicode_text_unsafe(text):
+                raise RuntimeError("clipboard_busy_set")
+            after_seq = self._clipboard_get_sequence()
+        finally:
+            self._clipboard_close()
+
+        time.sleep(max(0.01, clipboard_settle_ms / 1000.0))
+        self._send_paste_hotkey(is_terminal=is_terminal)
+
+        # Restore previous clipboard ONLY if unchanged (prevents clobbering user copies).
+        time.sleep(max(0.30, restore_delay_ms / 1000.0))
+        if not self._clipboard_open_retry():
+            return
+        try:
+            now_seq = self._clipboard_get_sequence()
+            current = self._clipboard_get_unicode_text_unsafe()
+            if (now_seq == after_seq) and (current == text):
+                if snapshot:
+                    self._clipboard_set_formats_unsafe(snapshot)
+                else:
+                    # Clipboard was empty before; restore empty.
+                    self._clipboard_set_formats_unsafe([])
+        finally:
+            self._clipboard_close()
 
     def type_text(self, text):
         """
         Inject text into active window.
-        SAFE MODE: Uses Clipboard for long text, but RESTORES previous clipboard.
+        Terminal-safe: paste in terminals (SSH/tmux friendly), type only very short text elsewhere.
+        Clipboard-safe: "borrow and restore" without clobbering user clipboard changes.
         """
         if not text:
             return
 
-        print(f"Injecting: {text}")
-        
-        # --- HYBRID MODE ---
-        if len(text) > 60:
+        self._refresh_config()
+        process_name = self._get_foreground_process_name()
+        is_terminal = self._is_terminal(process_name) and bool(settings.get("inject_terminal_always_paste"))
+        typing_max = int(settings.get("inject_typing_max_chars"))
+
+        use_paste = is_terminal or (len(text) > typing_max)
+        log(f"Injecting ({'paste' if use_paste else 'type'}) into {process_name or 'unknown'}: {text}", "debug")
+
+        if use_paste:
             try:
-                # 1. Save current clipboard
-                old_clipboard = pyperclip.paste()
-                
-                # 2. Inject new text via clipboard
-                pyperclip.copy(text)
-                time.sleep(0.05) # Wait for OS
-                
-                with self.keyboard.pressed(Key.ctrl):
-                    self.keyboard.type('v')
-                    
-                # 3. Restore old clipboard
-                # Wait for paste to consume the buffer (important!)
-                time.sleep(0.2) 
-                pyperclip.copy(old_clipboard)
-                
+                self._paste_via_clipboard(text, is_terminal=is_terminal)
                 return
             except Exception as e:
-                print(f"Clipboard Injection Failed: {e}")
-                pass # Fallback to typing
-
-        # Typing Mode (Short text or fallback)
-        try:
-            for char in text:
-                self.keyboard.type(char)
-                time.sleep(0.005) 
+                log(f"Clipboard Injection Failed: {e}", "warning")
+                # Fallback to typing (non-terminal only).
+                if is_terminal:
+                    return
+
+        try:
+            self.keyboard.type(text)
         except Exception as e:
-            print(f"Injection Failed: {e}")
+            log(f"Injection Failed: {e}", "error")
 
 if __name__ == "__main__":
     time.sleep(2)
--- a/core/settings.py
+++ b/core/settings.py
@@ -1,6 +1,7 @@
 import json
 import os
 import config
+from core.logger import log
 
 class SettingsManager:
     def __init__(self):
@@ -13,9 +14,111 @@
             "input_device_index": None, # Default device
             "use_intelligence": False, # Default to Raw Mode (User Preference)
             "transcription_language": "auto", # auto, en, fr
+
+            # Voice-activated mode (Discord-like) tuning
+            # Start gate = Silero speech probability + adaptive noise floor (RMS dBFS margin)
+            "voice_activation_start_confirm_ms": 220,
+            "voice_activation_hangover_ms": 160,
+            "voice_activation_cooldown_ms": 350,
+            "voice_activation_pre_roll_ms": 550,
+            "voice_activation_min_segment_ms": 450,
+            "voice_activation_min_speech_ms": 220,
+            "voice_activation_max_segment_s": 25.0,
+            "voice_activation_start_speech_prob": 0.62,
+            "voice_activation_stop_speech_prob": 0.45,
+            "voice_activation_start_db_margin": 8.0,
+            "voice_activation_stop_db_margin": 4.0,
+            "voice_activation_noise_update_speech_prob": 0.20,
+            "voice_activation_noise_ema_alpha": 0.04,
+
+            # Transcription stability (faster-whisper decode options)
+            "decode_beam_size": 8,
+            "decode_temperature": 0.0,
+            "decode_best_of": 1,
+            "decode_patience": 1.0,
+            "decode_length_penalty": 1.0,
+            "decode_repetition_penalty": 1.08,
+            "decode_no_repeat_ngram_size": 0,
+            "decode_condition_on_previous_text": True,
+            "decode_no_speech_threshold": 0.6,
+            "decode_log_prob_threshold": -1.0,
+            "decode_compression_ratio_threshold": 2.35,
+            "language_detection_threshold": 0.6,
+            "language_detection_segments": 2,
+
+            # Noisy-audio second pass (quality-first, may add ~0.2-1.0s)
+            "decode_enable_noisy_second_pass": True,
+            "decode_noisy_beam_size": 10,
+            "decode_noisy_best_of": 1,
+            "decode_noisy_condition_on_previous_text": False,
+
+            # Sticky language (prevents FR/EN flip-flop when language is set to "auto")
+            "sticky_language_enabled": True,
+            "sticky_language_min_prob": 0.80,
+            "sticky_language_ttl_s": 180.0,
+            "sticky_language_redetect_interval_s": 60.0,
+
+            # Confidence heuristics (reject likely hallucinations / noise-only captures)
+            "reject_no_speech_prob": 0.85,
+            "reject_avg_logprob": -0.95,
+            "reject_min_chars": 2,
+
+            # Confidence classification thresholds (used to decide retry/LLM/reject)
+            "conf_high_min_avg_logprob": -0.55,
+            "conf_high_max_avg_no_speech_prob": 0.55,
+            "conf_high_max_avg_compression_ratio": 2.05,
+            "conf_med_min_avg_logprob": -0.85,
+            "conf_med_max_avg_no_speech_prob": 0.78,
+            "conf_med_max_avg_compression_ratio": 2.35,
+
+            # Injection behavior
+            "inject_typing_max_chars": 32,
+            "inject_terminal_always_paste": True,
+            "inject_clipboard_settle_ms": 80,
+            "inject_clipboard_restore_delay_ms": 550,
+            "inject_clipboard_retry_count": 6,
+            "inject_clipboard_retry_backoff_ms": 20,
+            "terminal_processes": [
+                "windowsterminal.exe",
+                "wt.exe",
+                "conhost.exe",
+                "cmd.exe",
+                "powershell.exe",
+                "pwsh.exe",
+                "openconsole.exe",
+                "wezterm.exe",
+                "alacritty.exe",
+                "mintty.exe",
+                "tabby.exe",
+                "hyper.exe",
+                "putty.exe",
+            ],
+            "paste_hotkey_order": ["ctrl+shift+v", "shift+insert", "ctrl+v"],
+
+            # LLM refinement safety (Ollama)
+            "ollama_timeout_s": 6.0,
+            "llm_refine_max_chars": 420,
+            "llm_refine_skip_code_like": True,
+            "llm_refine_min_confidence": "high",  # high|medium|low
+
+            # Voice activation debug (logs segment summaries)
+            "voice_activation_debug": False,
+
+            # UI timing
+            "success_hold_ms": 350,
             "setup_completed": False
         }
         self.settings = self.load_settings()
+
+    def _warn_and_prune_unknown_keys(self, raw: dict) -> dict:
+        if not isinstance(raw, dict):
+            return {}
+
+        known = set(self.defaults.keys())
+        unknown = sorted([k for k in raw.keys() if k not in known])
+        if unknown:
+            log(f"Unknown settings keys ignored: {unknown}", "warning")
+        return {k: v for k, v in raw.items() if k in known}
 
     def load_settings(self):
         if not os.path.exists(self.settings_path):
@@ -24,6 +127,7 @@
         try:
             with open(self.settings_path, 'r') as f:
                 data = json.load(f)
+                data = self._warn_and_prune_unknown_keys(data)
                 # Merge with defaults to ensure all keys exist
                 merged = self.defaults.copy()
                 merged.update(data)
@@ -44,6 +148,9 @@
         return self.settings.get(key, self.defaults.get(key))
 
     def set(self, key, value):
+        if key not in self.defaults:
+            log(f"Attempt to set unknown setting ignored: {key}", "warning")
+            return
         self.settings[key] = value
         self.save_settings()
 
--- a/core/diagnostics.py
+++ b/core/diagnostics.py
@@ -0,0 +1,46 @@
+"""
+Manual, unit-ish diagnostics helpers.
+
+Run:
+  venv\\Scripts\\python -m core.diagnostics
+"""
+
+import json
+from core.logger import log
+from core.settings import manager as settings
+from core.transcriber import Transcriber
+
+
+def print_effective_decode_params():
+    t = Transcriber()
+    effective = t.dump_effective_decode_args()
+    print("=== Effective faster-whisper transcribe kwargs ===")
+    print(json.dumps(effective, indent=2))
+
+    # Also print current confidence thresholds.
+    print("\n=== Confidence thresholds ===")
+    keys = [
+        "reject_no_speech_prob",
+        "reject_avg_logprob",
+        "reject_min_chars",
+        "conf_high_min_avg_logprob",
+        "conf_high_max_avg_no_speech_prob",
+        "conf_high_max_avg_compression_ratio",
+        "conf_med_min_avg_logprob",
+        "conf_med_max_avg_no_speech_prob",
+        "conf_med_max_avg_compression_ratio",
+    ]
+    print(json.dumps({k: settings.get(k) for k in keys}, indent=2))
+
+
+def main():
+    try:
+        print_effective_decode_params()
+    except Exception as e:
+        log(f"Diagnostics failed: {e}", "error")
+        raise
+
+
+if __name__ == "__main__":
+    main()
+
--- a/ui/overlay.py
+++ b/ui/overlay.py
@@ -175,8 +175,11 @@
     # Check queue for updates
     timer = QTimer()
     def check_queue():
-        if not state_queue.empty():
+        # Drain to the latest state to avoid UI lag when updates come quickly.
+        state = None
+        while not state_queue.empty():
             state = state_queue.get()
+        if state is not None:
             widget.set_state(state)
     
     timer.timeout.connect(check_queue)
--- a/ui/settings_dialog.py
+++ b/ui/settings_dialog.py
@@ -70,8 +70,6 @@
                     self.device_combo.setCurrentIndex(self.device_combo.count() - 1)
         layout.addWidget(self.device_combo)
 
-        layout.addWidget(self.device_combo)
-
         # --- Language Lock ---
         layout.addWidget(QLabel("FORCE OUTPUT LANGUAGE"))
         self.lang_combo = QComboBox()
@@ -91,11 +89,19 @@
         layout.addWidget(self.lang_combo)
 
         # --- Visualizer ---
+        layout.addWidget(QLabel("MIC LEVEL"))
         self.meter = QProgressBar()
         self.meter.setRange(0, 100)
         self.meter.setTextVisible(False)
         self.meter.setFixedHeight(10)
         layout.addWidget(self.meter)
+
+        layout.addWidget(QLabel("SPEECH PROBABILITY (VAD)"))
+        self.vad_meter = QProgressBar()
+        self.vad_meter.setRange(0, 100)
+        self.vad_meter.setTextVisible(False)
+        self.vad_meter.setFixedHeight(10)
+        layout.addWidget(self.vad_meter)
         
         # Start Metering (Efficient)
         self.audio_engine.start_metering()
@@ -157,8 +163,15 @@
 
     def update_meter(self):
         level = self.audio_engine.get_current_volume()
-        val = min(100, int(level * 100))
+        val = min(100, int(level))
         self.meter.setValue(val)
+
+        vad_prob = 0.0
+        try:
+            vad_prob = float(self.audio_engine.get_current_speech_prob())
+        except Exception:
+            vad_prob = 0.0
+        self.vad_meter.setValue(max(0, min(100, int(vad_prob * 100))))
 
     def closeEvent(self, event):
         # Stop metering when closed (X or Done)
