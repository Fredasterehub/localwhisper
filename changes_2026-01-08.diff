--- a/config.py
+++ b/config.py
@@ -13,7 +13,7 @@
 # Whisper Settings
 WHISPER_MODEL_SIZE = "large-v3"
 # "float16" for GPU (requires VRAM), "int8" for efficiency if needed
-COMPUTE_TYPE = "int8" # Optimized for Speed/VRAM 
+COMPUTE_TYPE = "float16" # Optimized for semantic correctness on modern GPUs
 DEVICE = "cuda" # or "cpu"
 
 # Ollama Settings
--- a/main.py
+++ b/main.py
@@ -127,6 +127,7 @@
 
     processing_lock = threading.Lock()
     stop_processing_flag = False
+    success_hold_s = 0.35
     
     def pipeline_worker():
         nonlocal stop_processing_flag
@@ -172,7 +173,7 @@
                          
                          injector.type_text(final_text)
                          ui_queue.put("SUCCESS")
-                         time.sleep(1.0)
+                         time.sleep(success_hold_s)
                      else:
                          pass 
                  except Exception as e:
@@ -196,11 +197,14 @@
                         
                         raw_text = transcriber.transcribe(audio_data, language=lang_code)
                         if raw_text:
-                            final_text = intelligence.refine_text(raw_text)
-                        else:
-                            final_text = raw_text # Raw Mode
+                            if settings.get("use_intelligence"):
+                                final_text = intelligence.refine_text(raw_text)
+                            else:
+                                final_text = raw_text
+
+                            injector.type_text(final_text)
                             ui_queue.put("SUCCESS")
-                            time.sleep(1)
+                            time.sleep(success_hold_s)
                 except Exception:
                     pass
                 finally:
@@ -237,6 +241,48 @@
     
     threading.Thread(target=start_hotkey, daemon=True).start()
 
+    def start_ptt_key_listener():
+        # Optional single-key PTT binding from Settings (e.g., `, space).
+        ignore_keys = {"ctrl", "shift", "alt", "meta", "cmd", "win"}
+
+        def normalize_key(k):
+            try:
+                # KeyCode -> character (e.g. '`')
+                if hasattr(k, "char") and k.char:
+                    return str(k.char).lower()
+            except Exception:
+                pass
+
+            try:
+                # Special keys (space, enter, etc.)
+                if isinstance(k, keyboard.Key):
+                    name = str(k).replace("Key.", "").lower()
+                    return name
+            except Exception:
+                pass
+
+            return None
+
+        def on_press(k):
+            try:
+                if settings.get("mode") != "push_to_talk":
+                    return
+                wanted = str(settings.get("push_to_talk_key") or "").lower()
+                if not wanted or wanted in ignore_keys:
+                    return
+                if normalize_key(k) == wanted:
+                    trigger_ptt_pass()
+            except Exception:
+                pass
+
+        try:
+            with keyboard.Listener(on_press=on_press) as listener:
+                listener.join()
+        except Exception:
+            pass
+
+    threading.Thread(target=start_ptt_key_listener, daemon=True).start()
+
     def on_quit():
         stop_processing_flag = True
         if audio: audio.stop_recording()
--- a/core/audio.py
+++ b/core/audio.py
@@ -6,6 +6,7 @@
 import time
 import os
 import requests
+import math
 from core.settings import manager as settings
 from core.logger import log
 
@@ -19,7 +20,13 @@
         # Metering State
         self._metering = False
         self._current_vol = 0.0
+        self._current_speech_prob = 0.0
         self._meter_stream = None
+        self._meter_h = None
+        self._meter_c = None
+
+        # Voice-activation state (cooldown)
+        self._next_allowed_start_time = 0.0
         
         # Force CPU for VAD
         try:
@@ -37,12 +44,26 @@
         """Starts a background thread/stream for volume metering."""
         if self._metering: return
         self._metering = True
-        
+
         def meter_callback(indata, frames, time, status):
             if status:
                 print(status)
             vol = np.sqrt(np.mean(indata**2))
             self._current_vol = vol * 50 # Scale up
+
+            try:
+                # Estimate VAD speech probability for calibration in Settings UI.
+                # Uses a separate Silero state than the recording path.
+                if self._meter_h is None or self._meter_c is None:
+                    self._meter_h = np.zeros((2, 1, 64), dtype=np.float32)
+                    self._meter_c = np.zeros((2, 1, 64), dtype=np.float32)
+
+                chunk = indata.reshape(-1).astype(np.float32)
+                speech_prob, self._meter_h, self._meter_c = self._vad_iterator(chunk, self._meter_h, self._meter_c)
+                self._current_speech_prob = float(speech_prob)
+            except Exception:
+                # Never let UI metering crash audio callback.
+                pass
 
         try:
             device_idx = settings.get("input_device_index")
@@ -68,19 +89,26 @@
             self._meter_stream = None
         self._metering = False
         self._current_vol = 0.0
+        self._current_speech_prob = 0.0
+        self._meter_h = None
+        self._meter_c = None
         log("Metering stopped.", "info")
 
     def get_current_volume(self):
         """Returns the cached volume level (Instant)."""
         return self._current_vol
+
+    def get_current_speech_prob(self):
+        """Returns the cached Silero speech probability [0..1]."""
+        return self._current_speech_prob
     # --------------------------
 
     def download_vad_if_needed(self):
-         if not os.path.exists(self.vad_model_path) or os.path.getsize(self.vad_model_path) < 1000000:
+        if not os.path.exists(self.vad_model_path) or os.path.getsize(self.vad_model_path) < 1000000:
             url = "https://github.com/snakers4/silero-vad/raw/v4.0/files/silero_vad.onnx"
             try:
                 headers = {'User-Agent': 'Mozilla/5.0'}
-                r = requests.get(url, headers=headers, allow_redirects=True)
+                r = requests.get(url, headers=headers, allow_redirects=True, timeout=10)
                 if r.status_code == 200 and len(r.content) > 1000000:
                     with open(self.vad_model_path, 'wb') as f:
                         f.write(r.content)
@@ -104,64 +132,132 @@
     def stop_recording(self):
         self._running = False
 
+    @staticmethod
+    def _rms_dbfs(samples: np.ndarray) -> float:
+        # dB relative to full-scale for float audio in [-1..1].
+        rms = float(np.sqrt(np.mean(samples * samples))) if samples.size else 0.0
+        return 20.0 * math.log10(max(rms, 1e-8))
+
     def listen_single_segment(self):
         self._running = True
-        CHUNK_SIZE = 512
-        
-        threshold = settings.get("vad_threshold")
+        CHUNK_SIZE = int(getattr(config, "BLOCK_SIZE", 512))
+
+        threshold = float(settings.get("vad_threshold"))
         silence_dur = settings.get("silence_duration")
         device_idx = settings.get("input_device_index") 
-        
-        chunks_per_sec = self.sample_rate / CHUNK_SIZE
-        silence_chunks = int(silence_dur * chunks_per_sec)
-        
+
+        start_confirm_ms = int(settings.get("voice_activation_start_confirm_ms"))
+        hangover_ms = int(settings.get("voice_activation_hangover_ms"))
+        cooldown_ms = int(settings.get("voice_activation_cooldown_ms"))
+        pre_roll_ms = int(settings.get("voice_activation_pre_roll_ms"))
+        min_segment_ms = int(settings.get("voice_activation_min_segment_ms"))
+        min_speech_ms = int(settings.get("voice_activation_min_speech_ms"))
+        max_segment_s = float(settings.get("voice_activation_max_segment_s"))
+        start_speech_prob = float(settings.get("voice_activation_start_speech_prob"))
+        stop_speech_prob = float(settings.get("voice_activation_stop_speech_prob"))
+        start_db_margin = float(settings.get("voice_activation_start_db_margin"))
+        stop_db_margin = float(settings.get("voice_activation_stop_db_margin"))
+        noise_update_speech_prob = float(settings.get("voice_activation_noise_update_speech_prob"))
+        noise_ema_alpha = float(settings.get("voice_activation_noise_ema_alpha"))
+
+        # Backwards-compatible: allow the legacy single threshold to still affect gating.
+        start_speech_prob = max(start_speech_prob, threshold)
+        stop_speech_prob = min(stop_speech_prob, start_speech_prob - 0.08) if stop_speech_prob >= start_speech_prob else stop_speech_prob
+
+        chunk_ms = (CHUNK_SIZE / self.sample_rate) * 1000.0
+        start_confirm_chunks = max(1, int(math.ceil(start_confirm_ms / chunk_ms)))
+
         h = np.zeros((2, 1, 64), dtype=np.float32)
         c = np.zeros((2, 1, 64), dtype=np.float32)
-        
+
         triggered = False
         temp_buffer = []
         ring_buffer = [] 
-        ring_buffer_size = 30
-        silence_counter = 0
-        
-        log(f"Listening loop started (Thresh: {threshold:.2f})", "debug")
-        print(f"Listening (VAD: {threshold})...")
-        
+        ring_buffer_size = max(1, int(math.ceil(pre_roll_ms / chunk_ms)))
+
+        # Adaptive noise floor (dBFS) – updates only when we're confident we're NOT in speech.
+        noise_floor_db = -55.0
+        start_candidate_count = 0
+        speech_ms = 0.0
+        trigger_start_time = 0.0
+        last_speech_time = 0.0
+
+        now = time.time()
+        if now < self._next_allowed_start_time:
+            time.sleep(max(0.0, self._next_allowed_start_time - now))
+
         try:
-            with sd.InputStream(samplerate=self.sample_rate, device=device_idx, channels=1, blocksize=CHUNK_SIZE) as stream:
+            with sd.InputStream(
+                samplerate=self.sample_rate,
+                device=device_idx,
+                channels=1,
+                blocksize=CHUNK_SIZE,
+                dtype="float32",
+            ) as stream:
                 while self._running:
                     data, overflowed = stream.read(CHUNK_SIZE)
                     data = data.flatten()
-                    
+
                     speech_prob, h, c = self._vad_iterator(data, h, c)
-                    
+                    rms_db = self._rms_dbfs(data)
+
                     if not triggered:
                         ring_buffer.append(data)
                         if len(ring_buffer) > ring_buffer_size:
                             ring_buffer.pop(0)
-                        
-                        if speech_prob > threshold:
-                            print(f"Voice: {speech_prob:.2f}")
+
+                        # Update baseline noise floor when not in speech.
+                        if speech_prob <= noise_update_speech_prob:
+                            noise_floor_db = (1.0 - noise_ema_alpha) * noise_floor_db + noise_ema_alpha * rms_db
+
+                        # Start gate: require sustained speech probability AND energy above baseline.
+                        start_gate = (speech_prob >= start_speech_prob) and (rms_db >= (noise_floor_db + start_db_margin))
+                        if start_gate:
+                            start_candidate_count += 1
+                        else:
+                            start_candidate_count = 0
+
+                        if start_candidate_count >= start_confirm_chunks:
                             triggered = True
+                            trigger_start_time = time.time()
+                            last_speech_time = trigger_start_time
                             temp_buffer.extend(ring_buffer)
-                            temp_buffer.append(data)
-                            silence_counter = 0
+                            speech_ms = start_confirm_chunks * chunk_ms
                     else:
                         temp_buffer.append(data)
-                        if speech_prob < threshold:
-                            silence_counter += 1
+
+                        # Track "speech present" with hysteresis + energy margin.
+                        speech_present = (speech_prob >= stop_speech_prob) or (rms_db >= (noise_floor_db + stop_db_margin))
+                        if speech_present:
+                            last_speech_time = time.time()
+                            speech_ms += chunk_ms
                         else:
-                            silence_counter = 0
-                            
-                        if silence_counter > silence_chunks:
-                            print("Silence.")
+                            # Allow baseline to creep upwards during non-speech, even after trigger (e.g., steady fan/music).
+                            if speech_prob <= noise_update_speech_prob:
+                                noise_floor_db = (1.0 - noise_ema_alpha) * noise_floor_db + noise_ema_alpha * rms_db
+
+                        # Stop gate: end after sustained silence + hangover.
+                        effective_silence_s = float(silence_dur) + (hangover_ms / 1000.0)
+                        if (time.time() - last_speech_time) >= effective_silence_s:
                             break
-                            
+
+                        # Safety: prevent infinite segments on continuous background noise.
+                        if (time.time() - trigger_start_time) >= max_segment_s:
+                            log("Max segment duration reached; cutting segment.", "warning")
+                            break
+
             if not self._running:
                 log("Recording interrupted.", "info")
                 return np.array([], dtype=np.float32)
-                
-            return np.concatenate(temp_buffer)
+
+            # Reject very short or likely-false triggers.
+            total_ms = (time.time() - trigger_start_time) * 1000.0 if triggered else 0.0
+            if (not triggered) or (total_ms < min_segment_ms) or (speech_ms < min_speech_ms):
+                self._next_allowed_start_time = time.time() + (cooldown_ms / 1000.0)
+                return np.array([], dtype=np.float32)
+
+            self._next_allowed_start_time = time.time() + (cooldown_ms / 1000.0)
+            return np.concatenate(temp_buffer).astype(np.float32)
         except Exception as e:
             log(f"Recording Exception: {e}", "error")
             print(f"Recording Error: {e}")
--- a/core/transcriber.py
+++ b/core/transcriber.py
@@ -2,6 +2,8 @@
 import config
 import os
 import time
+from core.settings import manager as settings
+from core.logger import log
 
 class Transcriber:
     def __init__(self):
@@ -15,6 +17,34 @@
         )
         print(f"Model loaded in {time.time() - start:.2f}s")
 
+        self._sticky_language = None
+        self._sticky_set_time = 0.0
+        self._last_redetect_time = 0.0
+
+    def _choose_language(self, requested_language: str | None) -> str | None:
+        if requested_language:
+            return requested_language
+
+        if settings.get("transcription_language") != "auto":
+            return settings.get("transcription_language")
+
+        if not settings.get("sticky_language_enabled"):
+            return None
+
+        ttl_s = float(settings.get("sticky_language_ttl_s"))
+        redetect_interval_s = float(settings.get("sticky_language_redetect_interval_s"))
+        now = time.time()
+
+        # Periodically allow re-detection to enable deliberate language switching.
+        if (now - self._last_redetect_time) >= redetect_interval_s:
+            self._last_redetect_time = now
+            return None
+
+        if self._sticky_language and (now - self._sticky_set_time) <= ttl_s:
+            return self._sticky_language
+
+        return None
+
     def transcribe(self, audio_data, language=None):
         """
         Transcribe raw audio data (numpy array).
@@ -23,12 +53,71 @@
         if audio_data.dtype != "float32":
             audio_data = audio_data.astype("float32")
 
-        # Use passed language (or None for auto)
-        segments,info = self.model.transcribe(audio_data, beam_size=5, language=language, task="transcribe")
-        
+        chosen_language = self._choose_language(language)
+
+        beam_size = int(settings.get("decode_beam_size"))
+        temperature = float(settings.get("decode_temperature"))
+        best_of = int(settings.get("decode_best_of"))
+        patience = float(settings.get("decode_patience"))
+        length_penalty = float(settings.get("decode_length_penalty"))
+        repetition_penalty = float(settings.get("decode_repetition_penalty"))
+        no_repeat_ngram_size = int(settings.get("decode_no_repeat_ngram_size"))
+        condition_on_previous_text = bool(settings.get("decode_condition_on_previous_text"))
+        no_speech_threshold = float(settings.get("decode_no_speech_threshold"))
+        log_prob_threshold = float(settings.get("decode_log_prob_threshold"))
+        compression_ratio_threshold = float(settings.get("decode_compression_ratio_threshold"))
+        language_detection_threshold = float(settings.get("language_detection_threshold"))
+        language_detection_segments = int(settings.get("language_detection_segments"))
+
+        segments, info = self.model.transcribe(
+            audio_data,
+            task="transcribe",
+            language=chosen_language,
+            beam_size=beam_size,
+            temperature=temperature,
+            best_of=best_of,
+            patience=patience,
+            length_penalty=length_penalty,
+            repetition_penalty=repetition_penalty,
+            no_repeat_ngram_size=no_repeat_ngram_size,
+            condition_on_previous_text=condition_on_previous_text,
+            no_speech_threshold=no_speech_threshold,
+            log_prob_threshold=log_prob_threshold,
+            compression_ratio_threshold=compression_ratio_threshold,
+            language_detection_threshold=language_detection_threshold,
+            language_detection_segments=language_detection_segments,
+            vad_filter=False,
+            word_timestamps=False,
+        )
+
         # Collect all text
-        text = " ".join([segment.text for segment in segments])
-        return text.strip()
+        segments = list(segments)
+        text = " ".join([segment.text for segment in segments]).strip()
+
+        # Confidence heuristics: reject likely-noise segments to avoid "deconne" text injection.
+        min_chars = int(settings.get("reject_min_chars"))
+        if len(text) < min_chars:
+            return ""
+
+        try:
+            avg_no_speech = sum(float(s.no_speech_prob) for s in segments) / max(1, len(segments))
+            avg_logprob = sum(float(s.avg_logprob) for s in segments) / max(1, len(segments))
+            reject_no_speech_prob = float(settings.get("reject_no_speech_prob"))
+            reject_avg_logprob = float(settings.get("reject_avg_logprob"))
+            if avg_no_speech >= reject_no_speech_prob and avg_logprob <= reject_avg_logprob:
+                log(f"Rejected transcription (avg_no_speech={avg_no_speech:.2f}, avg_logprob={avg_logprob:.2f}).", "warning")
+                return ""
+        except Exception:
+            pass
+
+        # Update sticky language only when auto-detect was used.
+        if chosen_language is None and settings.get("sticky_language_enabled"):
+            min_prob = float(settings.get("sticky_language_min_prob"))
+            if getattr(info, "language_probability", 0.0) >= min_prob and getattr(info, "language", None):
+                self._sticky_language = info.language
+                self._sticky_set_time = time.time()
+
+        return text
 
 if __name__ == "__main__":
     t = Transcriber()
--- a/core/intelligence.py
+++ b/core/intelligence.py
@@ -1,72 +1,145 @@
+import re
 import requests
+
 import config
-import json
+from core.logger import log
+from core.settings import manager as settings
+
 
 class IntelligenceEngine:
     def __init__(self):
         self.url = config.OLLAMA_URL
         self.model = config.OLLAMA_MODEL
         print(f"Intelligence Engine connected to {self.model} at {self.url}")
-        
-    def refine_text(self, text):
+
+    @staticmethod
+    def _is_code_like(text: str) -> bool:
+        t = text.strip()
+        if not t:
+            return True
+
+        # Multi-line output is overwhelmingly terminal output / code / logs.
+        if "\n" in t or "\r" in t:
+            return True
+
+        # High-signal CLI/code markers.
+        code_markers = [
+            " --",
+            "--",
+            " -",
+            " /",
+            "\\",
+            "/",
+            "::",
+            "://",
+            "@",
+            "$",
+            "|",
+            "&&",
+            "||",
+            ";",
+            ">>",
+            "<<",
+            "{",
+            "}",
+            "[",
+            "]",
+            "(",
+            ")",
+            "<",
+            ">",
+            "=>",
+            "==",
+            "!=",
+            ":\\",
+            "~/",
+            "#",
+            "`",
+        ]
+        if any(m in t for m in code_markers):
+            return True
+
+        if re.search(r"\b([A-Za-z]:\\|/home/|/usr/|/etc/|~\/)\b", t):
+            return True
+        if re.search(r"(^|\s)--?[A-Za-z0-9][A-Za-z0-9_-]*", t):
+            return True
+        if re.search(r"\b(sudo|ssh|scp|rsync|tmux|vim|nvim|nano|git|pip|conda|docker|kubectl|helm)\b", t):
+            return True
+        if re.search(r"(^|\s)[A-Za-z_][A-Za-z0-9_]*=", t):
+            return True
+
+        # High symbol density => likely technical.
+        symbol_count = sum(1 for ch in t if not (ch.isalpha() or ch.isspace()))
+        if symbol_count / max(1, len(t)) >= 0.18:
+            return True
+
+        return False
+
+    def _should_refine(self, text: str) -> bool:
         if not text or len(text.strip()) < 2:
+            return False
+        if len(text) > int(settings.get("llm_refine_max_chars")):
+            return False
+        if settings.get("llm_refine_skip_code_like") and self._is_code_like(text):
+            return False
+        return True
+
+    def refine_text(self, text: str) -> str:
+        if not self._should_refine(text):
             return text
 
-        # System prompt optimized with 2026 best practices
-        system_prompt = (
-            "You are a minimal grammar correction assistant.\n\n"
-            "## TASK\n"
-            "Fix ONLY spelling errors and verb conjugation mistakes.\n"
-            "Make MINIMAL changes - preserve the user's exact wording, style, and sentence structure.\n\n"
-
-            "## CRITICAL RULES\n"
-            "1. Fix spelling mistakes (écrir → écrire, brokan → broken)\n"
-            "2. Fix verb conjugations (salute → salue, march → marche)\n"
-            "3. Fix obvious typos caused by thick accent (ze → the)\n"
-            "4. Remove filler words ONLY: euh, um, ah, like\n"
-            "5. PRESERVE the exact same words (do NOT use synonyms)\n"
-            "6. PRESERVE the sentence structure (do NOT reorganize)\n"
-            "7. PRESERVE punctuation (do NOT add commas/periods unless critical)\n"
-            "8. Keep the SAME language (French stays French, English stays English)\n\n"
-
-            "## EXAMPLES\n"
-            "Input: 'bonjour le docker il march pas'\n"
-            "Output: 'bonjour le docker il marche pas'\n\n"
-
-            "Input: 'je suis en train de t'écrir et cela fonctionne'\n"
-            "Output: 'je suis en train de t'écrire et cela fonctionne'\n\n"
-
-            "Input: 'hello ze code is brokan'\n"
-            "Output: 'hello the code is broken'\n\n"
-
-            "Input: 'euh je salute mon ami from Montréal'\n"
-            "Output: 'je salue mon ami from Montréal'\n\n"
-
-            "## OUTPUT FORMAT\n"
-            "Return ONLY the corrected text. No explanations, no quotes, no comments."
+        prompt = (
+            "You are a STRICT copy editor for dictated prose.\n"
+            "Return ONLY the corrected text. No quotes, no explanations.\n\n"
+            "Rules:\n"
+            "1) Preserve meaning exactly. Do NOT paraphrase.\n"
+            "2) Do NOT translate or change language.\n"
+            "3) Fix only: obvious spelling, obvious homophone mistakes, basic punctuation, capitalization.\n"
+            "4) Remove only these fillers when standalone words: euh, um, uh, ah, like.\n"
+            "5) Preserve whitespace (including leading/trailing spaces).\n"
+            "6) If unsure, output the input unchanged.\n\n"
+            "Input:\n"
+            "<<<\n"
+            f"{text}\n"
+            ">>>\n"
+            "Corrected:\n"
         )
 
         payload = {
             "model": config.OLLAMA_MODEL,
-            "prompt": f"{system_prompt}\nInput: '{text}'\nOutput:",
+            "prompt": prompt,
             "stream": False,
             "options": {
-                "temperature": 0.0 # STRICT. No creativity. Deterministic.
-            }
+                "temperature": 0.0,
+            },
         }
 
         try:
-            response = requests.post(self.url, json=payload)
+            response = requests.post(
+                self.url,
+                json=payload,
+                timeout=float(settings.get("ollama_timeout_s")),
+            )
             response.raise_for_status()
             result = response.json()
-            corrected = result.get("response", "").strip()
-            # Remove any wrapping quotes if mistakenly added by LLM
+            corrected = (result.get("response", "") or "").strip()
+
             if corrected.startswith('"') and corrected.endswith('"'):
                 corrected = corrected[1:-1]
+
+            if not corrected:
+                return text
+
+            # Safety: if the model output diverges wildly, skip refinement.
+            if abs(len(corrected) - len(text)) > max(80, int(len(text) * 0.6)):
+                log("LLM output length diverged; skipping refinement.", "warning")
+                return text
+
             return corrected
         except Exception as e:
-            print(f"Ollama Error: {e}")
-            return text # Fallback to original
+            log(f"Ollama Error: {e}", "warning")
+            return text
+
 
 if __name__ == "__main__":
     eng = IntelligenceEngine()
--- a/core/injector.py
+++ b/core/injector.py
@@ -1,52 +1,164 @@
 import time
 import sys
 import pyperclip
+import os
+import ctypes
+from ctypes import wintypes
 from pynput.keyboard import Controller, Key
+from core.settings import manager as settings
+from core.logger import log
 
 class Injector:
     def __init__(self):
         self.keyboard = Controller()
+        self._terminal_processes = {
+            "windowsterminal.exe",
+            "wt.exe",
+            "conhost.exe",
+            "cmd.exe",
+            "powershell.exe",
+            "pwsh.exe",
+            "openconsole.exe",
+            "wezterm.exe",
+            "alacritty.exe",
+            "mintty.exe",
+            "tabby.exe",
+            "hyper.exe",
+            "putty.exe",
+        }
+
+    @staticmethod
+    def _get_foreground_process_name() -> str | None:
+        try:
+            user32 = ctypes.WinDLL("user32", use_last_error=True)
+            kernel32 = ctypes.WinDLL("kernel32", use_last_error=True)
+
+            GetForegroundWindow = user32.GetForegroundWindow
+            GetForegroundWindow.restype = wintypes.HWND
+
+            GetWindowThreadProcessId = user32.GetWindowThreadProcessId
+            GetWindowThreadProcessId.argtypes = [wintypes.HWND, ctypes.POINTER(wintypes.DWORD)]
+            GetWindowThreadProcessId.restype = wintypes.DWORD
+
+            QueryFullProcessImageNameW = kernel32.QueryFullProcessImageNameW
+            QueryFullProcessImageNameW.argtypes = [wintypes.HANDLE, wintypes.DWORD, wintypes.LPWSTR, ctypes.POINTER(wintypes.DWORD)]
+            QueryFullProcessImageNameW.restype = wintypes.BOOL
+
+            OpenProcess = kernel32.OpenProcess
+            OpenProcess.argtypes = [wintypes.DWORD, wintypes.BOOL, wintypes.DWORD]
+            OpenProcess.restype = wintypes.HANDLE
+
+            CloseHandle = kernel32.CloseHandle
+            CloseHandle.argtypes = [wintypes.HANDLE]
+            CloseHandle.restype = wintypes.BOOL
+
+            hwnd = GetForegroundWindow()
+            if not hwnd:
+                return None
+
+            pid = wintypes.DWORD(0)
+            GetWindowThreadProcessId(hwnd, ctypes.byref(pid))
+            if not pid.value:
+                return None
+
+            PROCESS_QUERY_LIMITED_INFORMATION = 0x1000
+            hproc = OpenProcess(PROCESS_QUERY_LIMITED_INFORMATION, False, pid.value)
+            if not hproc:
+                return None
+
+            try:
+                buf_len = wintypes.DWORD(260)
+                buf = ctypes.create_unicode_buffer(buf_len.value)
+                if not QueryFullProcessImageNameW(hproc, 0, buf, ctypes.byref(buf_len)):
+                    return None
+                exe = os.path.basename(buf.value).lower()
+                return exe or None
+            finally:
+                CloseHandle(hproc)
+        except Exception:
+            return None
+
+    def _is_terminal(self, process_name: str | None) -> bool:
+        if not process_name:
+            return False
+        return process_name.lower() in self._terminal_processes
+
+    def _send_paste_hotkey(self, is_terminal: bool):
+        # Terminal-friendly ordering: Ctrl+Shift+V (modern terminals) -> Shift+Insert -> Ctrl+V
+        if is_terminal:
+            try:
+                with self.keyboard.pressed(Key.ctrl):
+                    with self.keyboard.pressed(Key.shift):
+                        self.keyboard.type("v")
+                return
+            except Exception:
+                pass
+
+            try:
+                with self.keyboard.pressed(Key.shift):
+                    self.keyboard.press(Key.insert)
+                    self.keyboard.release(Key.insert)
+                return
+            except Exception:
+                pass
+
+        with self.keyboard.pressed(Key.ctrl):
+            self.keyboard.type("v")
+
+    def _paste_via_clipboard(self, text: str, is_terminal: bool):
+        clipboard_settle_ms = int(settings.get("inject_clipboard_settle_ms"))
+        restore_delay_ms = int(settings.get("inject_clipboard_restore_delay_ms"))
+
+        old_clipboard = None
+        try:
+            old_clipboard = pyperclip.paste()
+        except Exception:
+            old_clipboard = None
+
+        try:
+            pyperclip.copy(text)
+            time.sleep(max(0.01, clipboard_settle_ms / 1000.0))
+            self._send_paste_hotkey(is_terminal=is_terminal)
+        finally:
+            # Restore previous clipboard ONLY if unchanged (prevents clobbering user copies).
+            try:
+                time.sleep(max(0.30, restore_delay_ms / 1000.0))
+                current = pyperclip.paste()
+                if current == text and old_clipboard is not None:
+                    pyperclip.copy(old_clipboard)
+            except Exception:
+                pass
 
     def type_text(self, text):
         """
         Inject text into active window.
-        SAFE MODE: Uses Clipboard for long text, but RESTORES previous clipboard.
+        Terminal-safe: paste in terminals (SSH/tmux friendly), type only very short text elsewhere.
+        Clipboard-safe: "borrow and restore" without clobbering user clipboard changes.
         """
         if not text:
             return
 
-        print(f"Injecting: {text}")
-        
-        # --- HYBRID MODE ---
-        if len(text) > 60:
+        process_name = self._get_foreground_process_name()
+        is_terminal = self._is_terminal(process_name) and bool(settings.get("inject_terminal_always_paste"))
+        typing_max = int(settings.get("inject_typing_max_chars"))
+
+        use_paste = is_terminal or (len(text) > typing_max)
+        log(f"Injecting ({'paste' if use_paste else 'type'}) into {process_name or 'unknown'}: {text}", "debug")
+
+        if use_paste:
             try:
-                # 1. Save current clipboard
-                old_clipboard = pyperclip.paste()
-                
-                # 2. Inject new text via clipboard
-                pyperclip.copy(text)
-                time.sleep(0.05) # Wait for OS
-                
-                with self.keyboard.pressed(Key.ctrl):
-                    self.keyboard.type('v')
-                    
-                # 3. Restore old clipboard
-                # Wait for paste to consume the buffer (important!)
-                time.sleep(0.2) 
-                pyperclip.copy(old_clipboard)
-                
+                self._paste_via_clipboard(text, is_terminal=is_terminal)
                 return
             except Exception as e:
-                print(f"Clipboard Injection Failed: {e}")
-                pass # Fallback to typing
+                log(f"Clipboard Injection Failed: {e}", "warning")
+                # Fallback to typing (non-terminal only).
+                if is_terminal:
+                    return
 
-        # Typing Mode (Short text or fallback)
         try:
-            for char in text:
-                self.keyboard.type(char)
-                time.sleep(0.005) 
+            self.keyboard.type(text)
         except Exception as e:
-            print(f"Injection Failed: {e}")
+            log(f"Injection Failed: {e}", "error")
 
 if __name__ == "__main__":
     time.sleep(2)
--- a/core/settings.py
+++ b/core/settings.py
@@ -13,6 +13,59 @@
             "input_device_index": None, # Default device
             "use_intelligence": False, # Default to Raw Mode (User Preference)
             "transcription_language": "auto", # auto, en, fr
+
+            # Voice-activated mode (Discord-like) tuning
+            # Start gate = Silero speech probability + adaptive noise floor (RMS dBFS margin)
+            "voice_activation_start_confirm_ms": 220,
+            "voice_activation_hangover_ms": 160,
+            "voice_activation_cooldown_ms": 350,
+            "voice_activation_pre_roll_ms": 550,
+            "voice_activation_min_segment_ms": 450,
+            "voice_activation_min_speech_ms": 220,
+            "voice_activation_max_segment_s": 25.0,
+            "voice_activation_start_speech_prob": 0.62,
+            "voice_activation_stop_speech_prob": 0.45,
+            "voice_activation_start_db_margin": 8.0,
+            "voice_activation_stop_db_margin": 4.0,
+            "voice_activation_noise_update_speech_prob": 0.20,
+            "voice_activation_noise_ema_alpha": 0.04,
+
+            # Transcription stability (faster-whisper decode options)
+            "decode_beam_size": 8,
+            "decode_temperature": 0.0,
+            "decode_best_of": 1,
+            "decode_patience": 1.0,
+            "decode_length_penalty": 1.0,
+            "decode_repetition_penalty": 1.08,
+            "decode_no_repeat_ngram_size": 0,
+            "decode_condition_on_previous_text": False,
+            "decode_no_speech_threshold": 0.6,
+            "decode_log_prob_threshold": -1.0,
+            "decode_compression_ratio_threshold": 2.35,
+            "language_detection_threshold": 0.6,
+            "language_detection_segments": 2,
+
+            # Sticky language (prevents FR/EN flip-flop when language is set to "auto")
+            "sticky_language_enabled": True,
+            "sticky_language_min_prob": 0.80,
+            "sticky_language_ttl_s": 180.0,
+            "sticky_language_redetect_interval_s": 60.0,
+
+            # Confidence heuristics (reject likely hallucinations / noise-only captures)
+            "reject_no_speech_prob": 0.85,
+            "reject_avg_logprob": -0.95,
+            "reject_min_chars": 2,
+
+            # Injection behavior
+            "inject_typing_max_chars": 32,
+            "inject_terminal_always_paste": True,
+            "inject_clipboard_settle_ms": 80,
+            "inject_clipboard_restore_delay_ms": 550,
+
+            # LLM refinement safety (Ollama)
+            "ollama_timeout_s": 6.0,
+            "llm_refine_max_chars": 420,
+            "llm_refine_skip_code_like": True,
             "setup_completed": False
         }
         self.settings = self.load_settings()
--- a/ui/overlay.py
+++ b/ui/overlay.py
@@ -175,8 +175,11 @@
     # Check queue for updates
     timer = QTimer()
     def check_queue():
-        if not state_queue.empty():
+        # Drain to the latest state to avoid UI lag when updates come quickly.
+        state = None
+        while not state_queue.empty():
             state = state_queue.get()
+        if state is not None:
             widget.set_state(state)
     
     timer.timeout.connect(check_queue)
--- a/ui/settings_dialog.py
+++ b/ui/settings_dialog.py
@@ -91,11 +91,19 @@
         layout.addWidget(self.lang_combo)
 
         # --- Visualizer ---
+        layout.addWidget(QLabel("MIC LEVEL"))
         self.meter = QProgressBar()
         self.meter.setRange(0, 100)
         self.meter.setTextVisible(False)
         self.meter.setFixedHeight(10)
         layout.addWidget(self.meter)
+
+        layout.addWidget(QLabel("SPEECH PROBABILITY (VAD)"))
+        self.vad_meter = QProgressBar()
+        self.vad_meter.setRange(0, 100)
+        self.vad_meter.setTextVisible(False)
+        self.vad_meter.setFixedHeight(10)
+        layout.addWidget(self.vad_meter)
         
         # Start Metering (Efficient)
         self.audio_engine.start_metering()
@@ -157,8 +165,15 @@
 
     def update_meter(self):
         level = self.audio_engine.get_current_volume()
-        val = min(100, int(level * 100))
+        val = min(100, int(level))
         self.meter.setValue(val)
+
+        vad_prob = 0.0
+        try:
+            vad_prob = float(self.audio_engine.get_current_speech_prob())
+        except Exception:
+            vad_prob = 0.0
+        self.vad_meter.setValue(max(0, min(100, int(vad_prob * 100))))
 
     def closeEvent(self, event):
         # Stop metering when closed (X or Done)
